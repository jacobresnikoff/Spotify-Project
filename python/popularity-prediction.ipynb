{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Song Popularity from Audio Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the course of the Covid-19 pandemic, I have focused my studies on data science and predictive analytics. One day, as I was running to the sound of Kenny Loggins' \"Danger Zone,\" it hit me: it would be fascinating to investigate the relationships different aspects of music share with one another. In what ways can we describe different aspects of a song? What features are most important to determining a song's popularity; can we derive a model that, given data describing these features, can predict the popularity of a song?\n",
    "\n",
    "In the following investigation I hope to answer these questions. Thankfully, a dataset suited to helping me derive insights into answering these questions has been compiled and posted to Kaggle by Yamac Eren Ay. Ay's Spotify dataset contains over 170,000 songs collected from the Spotify Web API, SpotiPy.\n",
    "\n",
    "My plan for my investigation is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Map\n",
    "\n",
    "1. Data Cleaning and Initial Exploration\n",
    "2. Feature Engineering\n",
    "3. Exploratory Data Analysis\n",
    "4. Model Building with Hyperparameter Tuning\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, DoubleType, DateType, BooleanType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName('Spotify').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.22.120.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spotify</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2cc18cc070>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(header='True', inferSchema='True').csv('../data/songs.csv')\n",
    "\n",
    "df = df.withColumn('danceability', col('danceability').cast(DoubleType())) \\\n",
    "    .withColumn('duration_ms', col('duration_ms').cast(DoubleType())) \\\n",
    "    .withColumn('energy', col('energy').cast(DoubleType())) \\\n",
    "    .withColumn('explicit', col('explicit').cast(BooleanType())) \\\n",
    "    .withColumn('instrumentalness', col('instrumentalness').cast(DoubleType())) \\\n",
    "    .withColumn('key', col('key').cast(IntegerType())) \\\n",
    "    .withColumn('liveness', col('liveness').cast(DoubleType())) \\\n",
    "    .withColumn('loudness', col('loudness').cast(DoubleType())) \\\n",
    "    .withColumn('mode', col('mode').cast(BooleanType())) \\\n",
    "    .withColumn('popularity', col('popularity').cast(DoubleType())) \\\n",
    "    .withColumn('release_date', col('release_date').cast(DateType())) \\\n",
    "    .withColumn('speechiness', col('speechiness').cast(DoubleType())) \\\n",
    "    .withColumn('tempo', col('tempo').cast(DoubleType())) \\\n",
    "    .withColumn('valence', col('valence').cast(DoubleType())) \\\n",
    "    .withColumn('year', col('year').cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- acousticness: double (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- danceability: double (nullable = true)\n",
      " |-- duration_ms: double (nullable = true)\n",
      " |-- energy: double (nullable = true)\n",
      " |-- explicit: boolean (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- instrumentalness: double (nullable = true)\n",
      " |-- key: integer (nullable = true)\n",
      " |-- liveness: double (nullable = true)\n",
      " |-- loudness: double (nullable = true)\n",
      " |-- mode: boolean (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- release_date: date (nullable = true)\n",
      " |-- speechiness: double (nullable = true)\n",
      " |-- tempo: double (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- year: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_palette('Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row and Column Dimensions: (174389, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991000</td>\n",
       "      <td>['Mamie Smith']</td>\n",
       "      <td>0.598</td>\n",
       "      <td>168333</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0</td>\n",
       "      <td>0cS0A1fUEUd1EW3FcF8AEI</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3790</td>\n",
       "      <td>-12.628</td>\n",
       "      <td>0</td>\n",
       "      <td>Keep A Song In Your Soul</td>\n",
       "      <td>12</td>\n",
       "      <td>1920</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>149.976</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643000</td>\n",
       "      <td>[\"Screamin' Jay Hawkins\"]</td>\n",
       "      <td>0.852</td>\n",
       "      <td>150200</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0hbkKFIJm7Z05H8Zl9w30f</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>-7.261</td>\n",
       "      <td>0</td>\n",
       "      <td>I Put A Spell On You</td>\n",
       "      <td>7</td>\n",
       "      <td>1920-01-05</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>86.889</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993000</td>\n",
       "      <td>['Mamie Smith']</td>\n",
       "      <td>0.647</td>\n",
       "      <td>163827</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0</td>\n",
       "      <td>11m7laMUgmOKqI3oYzuhne</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>-12.098</td>\n",
       "      <td>1</td>\n",
       "      <td>Golfing Papa</td>\n",
       "      <td>4</td>\n",
       "      <td>1920</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>97.600</td>\n",
       "      <td>0.6890</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000173</td>\n",
       "      <td>['Oscar Velazquez']</td>\n",
       "      <td>0.730</td>\n",
       "      <td>422087</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0</td>\n",
       "      <td>19Lc5SfJJ5O1oaxY0fpwfh</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-7.311</td>\n",
       "      <td>1</td>\n",
       "      <td>True House Music - Xavier Santos &amp; Carlos Gomi...</td>\n",
       "      <td>17</td>\n",
       "      <td>1920-01-01</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>127.997</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295000</td>\n",
       "      <td>['Mixe']</td>\n",
       "      <td>0.704</td>\n",
       "      <td>165224</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1</td>\n",
       "      <td>2hJjbsLCytGsnAHfdsLejp</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>-6.036</td>\n",
       "      <td>0</td>\n",
       "      <td>Xuniverxe</td>\n",
       "      <td>2</td>\n",
       "      <td>1920-10-01</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>122.076</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness                    artists  danceability  duration_ms  energy  \\\n",
       "0      0.991000            ['Mamie Smith']         0.598       168333   0.224   \n",
       "1      0.643000  [\"Screamin' Jay Hawkins\"]         0.852       150200   0.517   \n",
       "2      0.993000            ['Mamie Smith']         0.647       163827   0.186   \n",
       "3      0.000173        ['Oscar Velazquez']         0.730       422087   0.798   \n",
       "4      0.295000                   ['Mixe']         0.704       165224   0.707   \n",
       "\n",
       "   explicit                      id  instrumentalness  key  liveness  \\\n",
       "0         0  0cS0A1fUEUd1EW3FcF8AEI          0.000522    5    0.3790   \n",
       "1         0  0hbkKFIJm7Z05H8Zl9w30f          0.026400    5    0.0809   \n",
       "2         0  11m7laMUgmOKqI3oYzuhne          0.000018    0    0.5190   \n",
       "3         0  19Lc5SfJJ5O1oaxY0fpwfh          0.801000    2    0.1280   \n",
       "4         1  2hJjbsLCytGsnAHfdsLejp          0.000246   10    0.4020   \n",
       "\n",
       "   loudness  mode                                               name  \\\n",
       "0   -12.628     0                           Keep A Song In Your Soul   \n",
       "1    -7.261     0                               I Put A Spell On You   \n",
       "2   -12.098     1                                       Golfing Papa   \n",
       "3    -7.311     1  True House Music - Xavier Santos & Carlos Gomi...   \n",
       "4    -6.036     0                                          Xuniverxe   \n",
       "\n",
       "   popularity release_date  speechiness    tempo  valence  year  \n",
       "0          12         1920       0.0936  149.976   0.6340  1920  \n",
       "1           7   1920-01-05       0.0534   86.889   0.9500  1920  \n",
       "2           4         1920       0.1740   97.600   0.6890  1920  \n",
       "3          17   1920-01-01       0.0425  127.997   0.0422  1920  \n",
       "4           2   1920-10-01       0.0768  122.076   0.2990  1920  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in csv\n",
    "spot = pd.read_csv('../data/songs.csv')\n",
    "\n",
    "# preview data\n",
    "print('Row and Column Dimensions: {}'.format(spot.shape), sep='\\n\\n')\n",
    "spot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 174389 entries, 0 to 174388\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   acousticness      174389 non-null  float64\n",
      " 1   artists           174389 non-null  object \n",
      " 2   danceability      174389 non-null  float64\n",
      " 3   duration_ms       174389 non-null  int64  \n",
      " 4   energy            174389 non-null  float64\n",
      " 5   explicit          174389 non-null  int64  \n",
      " 6   id                174389 non-null  object \n",
      " 7   instrumentalness  174389 non-null  float64\n",
      " 8   key               174389 non-null  int64  \n",
      " 9   liveness          174389 non-null  float64\n",
      " 10  loudness          174389 non-null  float64\n",
      " 11  mode              174389 non-null  int64  \n",
      " 12  name              174389 non-null  object \n",
      " 13  popularity        174389 non-null  int64  \n",
      " 14  release_date      174389 non-null  object \n",
      " 15  speechiness       174389 non-null  float64\n",
      " 16  tempo             174389 non-null  float64\n",
      " 17  valence           174389 non-null  float64\n",
      " 18  year              174389 non-null  int64  \n",
      "dtypes: float64(9), int64(6), object(4)\n",
      "memory usage: 25.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# get an overview of each column, the number of values in each, and their respective data types\n",
    "spot.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Objectives\n",
    "\n",
    "a) Check for duplicates\n",
    "\n",
    "b) Check for null values\n",
    "\n",
    "c) Determine features to drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Dealing with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2143254448388373\n"
     ]
    }
   ],
   "source": [
    "# find proportion of duplicate songs within dataset\n",
    "spot['name'].duplicated().value_counts()\n",
    "print(spot['name'].duplicated().value_counts()[1] / len(spot['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 20% of the data consists of duplicates. To obtain accurate results, it is best to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dupeDeleter(spotify_df, name_array):\n",
    "    '''replace duplicate entries with an associated metric with one entry and the mean of the metric; for spotify dataframe'''\n",
    "    \n",
    "    # create list of unique songs\n",
    "    unique_songs = pd.unique(name_array)\n",
    "    # instantiate empty dictionary\n",
    "    master = {}\n",
    "    # iterate through unique song list, assigning each song as a key and an empty list as its value\n",
    "    for song in unique_songs:\n",
    "        master[song] = []\n",
    "    \n",
    "    # iterate through integers to facilitate loop\n",
    "    for i in range(0, len(spotify_df)):\n",
    "        # access each song in dictionary by passing in its name, then append the current iterance's popularity score to the song's list\n",
    "        master[spotify_df.iloc[i,12]].append(spotify_df.iloc[i,13])\n",
    "    \n",
    "    # iterate through dictionary, splitting keys and values from each other\n",
    "    for key, value in master.items():\n",
    "        # append the mean of all popularity scores within the popularity score list as the final element\n",
    "        master[key].append(np.mean(master[key]))\n",
    "\n",
    "    # iterate through integers to facilitate loop\n",
    "    for i in range(0, len(spot)):\n",
    "        # access the song name, pass into dictionary to access list, access mean and impute the corresponding song's popularity score in the dataframe with mean\n",
    "        spotify_df.iloc[i,13] = master[spotify_df.iloc[i,12]][-1]\n",
    "\n",
    "    # drop duplicates and reset the dataframe integer indexing\n",
    "    spot.drop_duplicates(inplace=True)\n",
    "    spot.reset_index(inplace=True)\n",
    "    spot.drop('index', axis=1, inplace=True)\n",
    "\n",
    "    return spotify_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign spot dataframe as output of dupeDeleter\n",
    "spot = dupeDeleter(spotify_df=spot, name_array=spot['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, every occurence of every song in the dataframe has a popularity score of its mean across all duplicates. After dropping all duplicate entries, no one song shall be overrepresented when modeling.\n",
    "\n",
    "There are certainly other values to have imputed other than the mean, such as using the maximum of a song's popularity scores. Cleaning the duplicates in this way may introduce some bias, but it is likely the most pragmatic action to take given what information is available on how the popularity metric is computed by Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>major</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.598</td>\n",
       "      <td>168333</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3790</td>\n",
       "      <td>-12.628</td>\n",
       "      <td>0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>149.976</td>\n",
       "      <td>0.6340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>150200</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>-7.261</td>\n",
       "      <td>0</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>86.889</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.647</td>\n",
       "      <td>163827</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>-12.098</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>97.600</td>\n",
       "      <td>0.6890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.730</td>\n",
       "      <td>422087</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-7.311</td>\n",
       "      <td>1</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>127.997</td>\n",
       "      <td>0.0422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.704</td>\n",
       "      <td>165224</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>-6.036</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>122.076</td>\n",
       "      <td>0.2990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0      0.991000         0.598       168333   0.224         0   \n",
       "1      0.643000         0.852       150200   0.517         0   \n",
       "2      0.993000         0.647       163827   0.186         0   \n",
       "3      0.000173         0.730       422087   0.798         0   \n",
       "4      0.295000         0.704       165224   0.707         1   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  major  popularity  speechiness  \\\n",
       "0          0.000522    5    0.3790   -12.628      0   12.000000       0.0936   \n",
       "1          0.026400    5    0.0809    -7.261      0   41.333333       0.0534   \n",
       "2          0.000018    0    0.5190   -12.098      1    4.000000       0.1740   \n",
       "3          0.801000    2    0.1280    -7.311      1   17.000000       0.0425   \n",
       "4          0.000246   10    0.4020    -6.036      0    2.000000       0.0768   \n",
       "\n",
       "     tempo  valence  \n",
       "0  149.976   0.6340  \n",
       "1   86.889   0.9500  \n",
       "2   97.600   0.6890  \n",
       "3  127.997   0.0422  \n",
       "4  122.076   0.2990  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop artists, id, name, release_date, year\n",
    "spot.drop(['artists','id','name','release_date', 'year'], axis=1, inplace=True)\n",
    "spot.head()\n",
    "\n",
    "# rename mode to major, so as to clarify that 1 is major and 0 is minor\n",
    "spot.rename(mapper={'mode':'major'}, axis=1, inplace=True)\n",
    "spot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this investigation I will not be analyzing any trends related to individual artists or song titles, and the id is a residual identifier from the Spotipy API. I also dropped the year because I will not be incorporating any time-series elements for this particular project.\n",
    "\n",
    "It is best to keep the explicit and mode features binary, rather than converting them to strings (explicit or non-explicit, minor or major). If they remain encoded as dummy variables, they are great candidates for regression modeling. At this point, I decided to rename the mode feature to major, so as to clarify that 1 indicates that a song is major and 0 that a song is minor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Musical Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notationConverter(input_array, map_dict):\n",
    "    '''takes in an array of input, converts each element to the corresponding value from a provided dictionary'''\n",
    "    \n",
    "    # instantiate empty list\n",
    "    outputs = []\n",
    "\n",
    "    # iterate through input_array, for each element append the corresponding value from map_dict as a string to the output list\n",
    "    for i in input_array:\n",
    "        outputs.append(map_dict[i])\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>major</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.598</td>\n",
       "      <td>168333</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>F</td>\n",
       "      <td>0.3790</td>\n",
       "      <td>-12.628</td>\n",
       "      <td>0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>149.976</td>\n",
       "      <td>0.6340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>150200</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>-7.261</td>\n",
       "      <td>0</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>86.889</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.647</td>\n",
       "      <td>163827</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>C</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>-12.098</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>97.600</td>\n",
       "      <td>0.6890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.730</td>\n",
       "      <td>422087</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>D</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-7.311</td>\n",
       "      <td>1</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>127.997</td>\n",
       "      <td>0.0422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.704</td>\n",
       "      <td>165224</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>Bb</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>-6.036</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>122.076</td>\n",
       "      <td>0.2990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0      0.991000         0.598       168333   0.224         0   \n",
       "1      0.643000         0.852       150200   0.517         0   \n",
       "2      0.993000         0.647       163827   0.186         0   \n",
       "3      0.000173         0.730       422087   0.798         0   \n",
       "4      0.295000         0.704       165224   0.707         1   \n",
       "\n",
       "   instrumentalness key  liveness  loudness  major  popularity  speechiness  \\\n",
       "0          0.000522   F    0.3790   -12.628      0   12.000000       0.0936   \n",
       "1          0.026400   F    0.0809    -7.261      0   41.333333       0.0534   \n",
       "2          0.000018   C    0.5190   -12.098      1    4.000000       0.1740   \n",
       "3          0.801000   D    0.1280    -7.311      1   17.000000       0.0425   \n",
       "4          0.000246  Bb    0.4020    -6.036      0    2.000000       0.0768   \n",
       "\n",
       "     tempo  valence  \n",
       "0  149.976   0.6340  \n",
       "1   86.889   0.9500  \n",
       "2   97.600   0.6890  \n",
       "3  127.997   0.0422  \n",
       "4  122.076   0.2990  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary mapping musical keys in pitch class notation to keys, with the keys in letter form as the values\n",
    "pitchclass_map = {\n",
    "    0:'C',\n",
    "    1:'Db',\n",
    "    2:'D',\n",
    "    3:'Eb',\n",
    "    4:'E',\n",
    "    5:'F',\n",
    "    6:'Gb',\n",
    "    7:'G',\n",
    "    8:'Ab',\n",
    "    9:'A',\n",
    "    10:'Bb',\n",
    "    11:'B'\n",
    "}\n",
    "\n",
    "# get array of keys in pitch class notation for all observations\n",
    "pitchclass_input = spot['key']\n",
    "\n",
    "# pass array into function\n",
    "keys = notationConverter(input_array=pitchclass_input, map_dict=pitchclass_map)\n",
    "\n",
    "# convert output from list to pandas Series\n",
    "keys = pd.Series(keys)\n",
    "\n",
    "# replace pitch class notation array with key name array\n",
    "spot['key'] = keys\n",
    "spot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>major</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.598</td>\n",
       "      <td>2.805550</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>F</td>\n",
       "      <td>0.3790</td>\n",
       "      <td>-12.628</td>\n",
       "      <td>0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>149.976</td>\n",
       "      <td>0.6340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>2.503333</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>-7.261</td>\n",
       "      <td>0</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>86.889</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.647</td>\n",
       "      <td>2.730450</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>C</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>-12.098</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>97.600</td>\n",
       "      <td>0.6890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.730</td>\n",
       "      <td>7.034783</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>D</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-7.311</td>\n",
       "      <td>1</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>127.997</td>\n",
       "      <td>0.0422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.704</td>\n",
       "      <td>2.753733</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>Bb</td>\n",
       "      <td>0.4020</td>\n",
       "      <td>-6.036</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>122.076</td>\n",
       "      <td>0.2990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_min  energy  explicit  \\\n",
       "0      0.991000         0.598      2.805550   0.224         0   \n",
       "1      0.643000         0.852      2.503333   0.517         0   \n",
       "2      0.993000         0.647      2.730450   0.186         0   \n",
       "3      0.000173         0.730      7.034783   0.798         0   \n",
       "4      0.295000         0.704      2.753733   0.707         1   \n",
       "\n",
       "   instrumentalness key  liveness  loudness  major  popularity  speechiness  \\\n",
       "0          0.000522   F    0.3790   -12.628      0   12.000000       0.0936   \n",
       "1          0.026400   F    0.0809    -7.261      0   41.333333       0.0534   \n",
       "2          0.000018   C    0.5190   -12.098      1    4.000000       0.1740   \n",
       "3          0.801000   D    0.1280    -7.311      1   17.000000       0.0425   \n",
       "4          0.000246  Bb    0.4020    -6.036      0    2.000000       0.0768   \n",
       "\n",
       "     tempo  valence  \n",
       "0  149.976   0.6340  \n",
       "1   86.889   0.9500  \n",
       "2   97.600   0.6890  \n",
       "3  127.997   0.0422  \n",
       "4  122.076   0.2990  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change units of duration from ms to minutes\n",
    "spot['duration_ms'] = spot['duration_ms'] / 60000\n",
    "\n",
    "# rename column\n",
    "spot.rename(mapper={'duration_ms':'duration_min'}, axis=1, inplace=True)\n",
    "spot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the units of duration to minutes ought to result in a more intuitive analysis after passing the data into our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis - Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate numerical variables\n",
    "num_index = spot.describe().columns.drop(['explicit','major'])\n",
    "num = spot[num_index]\n",
    "num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute descriptive statistics of numerical variables\n",
    "num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize the distribution of each variable via histogram\n",
    "for col in num.columns:\n",
    "    if col.startswith('year') == False:\n",
    "        ax = sns.displot(x=col, kind='hist', data=num)\n",
    "        ax.fig.suptitle(col, size=14)\n",
    "    else:\n",
    "        ax = sns.displot(x=col, kind='hist', bins=10, data=num)\n",
    "        ax.fig.suptitle(col, size=14)\n",
    "        ax.set_xticklabels(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acousticness - \"A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\"\n",
    "\n",
    "Acousticness is quite polarized. Across the dataset, the Spotipy API attributed acousticness scores in what appears to be a bimodal or beta distribution. This seems reasonable given that this feature represents a confidence measure, and is thereby bounded between 0 and 1. The probability that Spotify has virtually no confidence or near absolute confidence that a given track is acoustic appears high compared to ambiguous cases. As is, this moreso provides information on the tendencies of Spotify's own classification models than anything else.\n",
    "\n",
    "Danceability - \"Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\"\n",
    "\n",
    "In contrast, danceability closely follows the normal distribution. It is skewed just slightly to the left, which in this case means the data's center is slightly biased towards higher levels of danceability.\n",
    "\n",
    "Duration_ms - \"The duration of the track in milliseconds.\"\n",
    "\n",
    "Each unit on the x-axis is in millions of milliseconds, meaning that one unit is equal to 1000 seconds or 16.67 minutes. For our analysis, it would likely be best to convert these values to seconds or minutes, which would lead to more intuitive insights. Most of the data appears to be between 0 and 16.67 minutes. This aligns with our intuition, where I imagine few people would want to listen to a single track lasting beyond 10 minutes or so. Inspecting the outliers might lead to additional insights.\n",
    "\n",
    "Energy - \"Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\"\n",
    "\n",
    "Energy appears to follow a right-skewed distribution. We may need to transform it before including it in any models. For now, it appears that the center of the distribution is somewhat skewed toward less energetic music.\n",
    "\n",
    "Instrumentalness - \"Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\"\n",
    "\n",
    "Instrumentalness appears right-skewed, demonstrating a tendency toward tracks with vocal content.\n",
    "\n",
    "Liveness - \"Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\"\n",
    "\n",
    "Liveness appears quite right-skewed, implying that a greater proportion of tracks are recorded in studio settings.\n",
    "\n",
    "Loudness - \"The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db.\"\n",
    "\n",
    "Each observation for loudness represents a track's average loudness level. Loudness appears quite left-skewed, showing a tendency toward high average loudnesses.\n",
    "\n",
    "Popularity - \"The popularity of the track. The value will be between 0 and 100, with 100 being the most popular. The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are.\"\n",
    "\n",
    "There are many songs with a popularity score of 0; beyond that appears to be one long tail that comprises a miniature distribution of its own. Hence, there are *many* tracks that are virtually unknown, with a relatively uniform probability than a given song has any popularity rating greater than 0.\n",
    "\n",
    "Speechiness - \"Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.\"\n",
    "\n",
    "The description for Speechiness is intriguing, insofar that it provides lower and upper bounds with which to categorize entries. This may be an interesting opportunity for feature engineering later on. There is also a tendency towards lower Speechiness values, implying a preference toward instrumental tracks. Given that high speechiness indicates more speech and high instrumentalness indicates less speech, we would expect these metrics to be inversely related.\n",
    "\n",
    "Tempo - \"The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\"\n",
    "\n",
    "Tempo appears to closely follow the normal distribution, with a center at roughly 120 beats per minute.\n",
    "\n",
    "Valence - \"A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\"\n",
    "\n",
    "Valence appears to have a multi-modal distribution. Many songs are clearly high-valence and clearly low-valence. The slight peak at a valence = 0.5 likely forms due to higher levels of uncertainty in classifying a song, plus the songs that contain both high-valence and low-valence elements.\n",
    "\n",
    "Year - As far as I can tell, it is a derivation of the release_date feature. It is not listed under the [Spotify Web API Documentation](https://developer.spotify.com/documentation/web-api/reference/#endpoint-get-audio-features) I've been referencing thus far.\n",
    "\n",
    "Songs across the dataset seem to be somewhat normally distributed across the past century, except the high number of songs that were released between 2010 and 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate categorical variables\n",
    "cat_index = spot.columns.drop(num.columns)\n",
    "cat = spot[cat_index]\n",
    "cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_cat_var = ['explicit','major','key']\n",
    "\n",
    "# visualize distribution of the levels of each categorical variable via barplots\n",
    "for var in discrete_cat_var:\n",
    "    ax = sns.catplot(x=var, kind='count', data=cat, palette='Greens')\n",
    "    ax.fig.suptitle(var, size=14)\n",
    "    if (var.startswith('explicit') == True) | (var.startswith('major') == True) :\n",
    "        counts = cat[var].value_counts()\n",
    "        prop_1 = counts[1] / (counts[0] + counts[1])\n",
    "        print('The proportion of songs that are ' + str(var) + ' is {:.2%}'.format(prop_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table exploring the relationships between the categorical variables\n",
    "ptable = pd.pivot_table(data=cat, index='key', values='major', columns='explicit', aggfunc='count')\n",
    "ptable['Proportion of Non-Explicit'] = ptable.iloc[:,0] / (ptable.iloc[:,0] + ptable.iloc[:,1])\n",
    "ptable['Proportion of Explicit'] = 1-ptable['Proportion of Non-Explicit']\n",
    "\n",
    "ptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort to find the keys that contain songs with the highest proportion of explicit content\n",
    "ptable.nlargest(n=4, columns='Proportion of Explicit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the binary variables explicit and mode (now renamed to major), a 0 indicates a song lacking expletives or in a minor key, whereas a 1 indicates a song with expletives or in a major key, respectively.\n",
    "\n",
    "The key feature refers to the musical key a song is, and is encoded in pitch-class notation. The key of C is encoded as 0, the key of C# as 1, etc. This is certainly a good candidate for feature engineering. This variable is not ordinal, so no valuable information would be lost from reverting these numbers back to their keys expressed in letters (which we did earlier). We may also derive the key signatures for these songs; perhaps there is some correlation with the number of sharps or flats a song has and its popularity? I suspect not, because key signatures are functions of each key, but it could be an interesting exercise for another time.\n",
    "\n",
    "From visual inspection, we see that songs written in the keys of C, G, D, and A occurred most frequently. In addition, the majority of tracks seem to be non-explicit and in a major key. The four keys with the highest proportion of songs that are explicit, as depicted by the above pivot table, are the keys of Db, B, Gb, and Ab. There is no overlap between the most frequently occuring keys and the keys with the highest proportion of songs that are explicit.\n",
    "\n",
    "I am intrigued to explore the relationship between the categorical variables key and mode with respect to the numerical variables valence and popularity. We would expect that happy songs (high-valence) are correlated with major = 1 (major key). For now, though, we'll stick with predicting popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mean popularity score for each musical key\n",
    "pd.pivot_table(spot, index='key', values='popularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the mean popularity for each key is roughly the same. I suspect that it won't affect our model outputs, but we'll have to investigate more to see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation heatmap\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    spot.corr(method='pearson'),\n",
    "    cmap='Greens',\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt='.2f'\n",
    ")\n",
    "\n",
    "ax.set_title('Correlation Heatmap of Song Features',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity seems to have a weak negative correlation with the confidence that a track is acoustic, implying that Spotify users may have a preference for digital music.\n",
    "\n",
    "There is a weak positive correlation with energy, implying preference for fast and loud tracks.\n",
    "\n",
    "This is validated by a similar weak positive correlation for loudness.\n",
    "\n",
    "Finally, Popularity has a moderate positive correlation with year. Based upon Spotipy's definition of Popularity, we likely cannot claim that modern music is more popular than older music. However, we might be able to infer that Spotify users tend to listen to newer songs more than older ones.\n",
    "\n",
    "Aside from popularity, loudness and energy appear to have a strong positive correlation. Energy and acousticness share a strong negative correlation. Valence and danceability also appear to share a moderate positive correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplots with target variable \"popularity\" on y-axes and predictor variables on x-axes\n",
    "# double click on any of the graphics to zoom in\n",
    "cols = ['acousticness', 'danceability', 'duration_min', 'energy', 'instrumentalness',\n",
    "       'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'year']\n",
    "\n",
    "ax = sns.pairplot(data=spot, x_vars=cols, y_vars='popularity', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although creating scatterplots to illuminate each predictor's relationship with popularity is usually helpful for intuition-building, the sheer volume of observations makes these visualizations difficult to interpret. All that's left for us is to build, run, and evaluate our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate predictor variables\n",
    "X = spot.drop('popularity', axis=1)\n",
    "\n",
    "# isolate target variable\n",
    "y = spot.popularity\n",
    "\n",
    "# isolate categorical and numerical feature names\n",
    "cat_predictors = ['explicit','key','major']\n",
    "num_predictors = ['acousticness','danceability','duration_min',\n",
    "                'energy','instrumentalness', 'liveness',\n",
    "                'loudness','speechiness','tempo','valence','year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# preprocessing for feature columns\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), cat_predictors),\n",
    "    (StandardScaler(), num_predictors),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in preprocessing and model steps into pipeline object\n",
    "pipeline = make_pipeline(preprocessor, knn)\n",
    "\n",
    "# create hyperparameter space for n_neighbors, with values increasing by 1 from 1 to 25\n",
    "params = {'kneighborsregressor__n_neighbors': np.arange(1, 26)}\n",
    "\n",
    "# subset training and test sets for the predictors and the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# standardize y_train and y_test (i.e. standardizing the target feature popularity)\n",
    "y_train, y_test = scale(y_train), scale(y_test)\n",
    "\n",
    "# perform grid search style cross validation to find the optimal value for the n_neighbors hyperparameter\n",
    "cv = GridSearchCV(pipeline, param_grid=params)\n",
    "\n",
    "# fit the model with optimized hyperparameters to training set\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# generate predictions for the test set\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "# print the optimal model parameters\n",
    "print(cv.best_params_)\n",
    "\n",
    "# print the optimal model r-squared value\n",
    "print(cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the use of Grid Search Cross Validation, we can determine that the optimal number of neighbors for the KNN Regressor is 25.\n",
    "\n",
    "Given the KNN Regressor model's Multiple $ R^{2} $ of 0.5674, 56.74% of the variation in popularity can be explained by the aforementioned predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and print root mean squared error of predictions and standard deviation of target variable\n",
    "rmse_knn = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(rmse_knn)\n",
    "print(rmse_knn/np.mean(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Least Squares Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "ols = LinearRegression()\n",
    "\n",
    "# preprocessing for feature columns\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), cat_predictors), # encode dummy variables for categorical features\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in preprocessing and model steps into pipeline object\n",
    "pipeline = make_pipeline(preprocessor, ols)\n",
    "\n",
    "# subset training and test sets for the predictors and the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# fit the model to the training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# generate predictions for the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# print the optimal model r-squared value\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the Ordinary Least Squares Regression model's Multiple $ R^{2} $ of 0.3965, 39.65% of the variation in popularity can be explained by the aforementioned predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate categorical feature names into a list\n",
    "feature_names = pipeline.named_steps['columntransformer'].named_transformers_['onehotencoder'].get_feature_names(input_features=cat_predictors)\n",
    "\n",
    "# concatenate categorical feature names and previous list of the names of numerical predictors\n",
    "feature_names = np.concatenate(\n",
    "    [feature_names, num_predictors])\n",
    "\n",
    "# create dataframe matching the name of each feature with its respective regression coefficient\n",
    "summary = pd.DataFrame(\n",
    "    pipeline.named_steps.linearregression.coef_,\n",
    "    columns=['Coefficients'], index=feature_names)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretation \n",
    " - Compared to non-explicit songs, on average an explicit song is associated with an increase in popularity rating of about 8.92\n",
    " - Compared to songs written in the Key of A, on average songs written in the Key of C are associated with an increase in popularity rating of about 0.17\n",
    " - A one unit increase in acousticness is, on average, associated with a 7.55 decrease in a song's popularity rating\n",
    " - A one unit increase in danceability is, on average, associated with a 2.31 decrease in a song's popularity rating\n",
    " - A one unit increase in energy is, on average, associated with a 2.44 decrease in a song's popularity rating\n",
    " - A one unit increase in instrumentalness is, on average, associated with a 14.63 decrease in a song's popularity rating\n",
    " - A one unit increase in liveness is, on average, associated with a 7.76 decrease in a song's popularity rating\n",
    " - A one unit increase in speechiness is, on average, associated with a 21.57 decrease in a song's popularity rating\n",
    " - A one unit increase in valence is, on average, associated with a 3.55 increase in a song's popularity rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and print root mean squared error of predictions and standard deviation of target variable\n",
    "rmse_ols = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(rmse_ols)\n",
    "print(rmse_ols/np.mean(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we standardized the numeric variables for the KNN Regressor model inputs but not in the OLS model inputs, we will attempt to compare their $ RMSE $ values by computing the $ NRMSE $ by dividing each by the mean of popularity in the test set.\n",
    "\n",
    "The KNN Regressor model possesses an $ RMSE = 0.658 $, and the $ NMRSE = -7403122586922790.0 $. The Ordinary Least Squares Regression model possesses an $ RMSE = 16.06 $, and the $ NMRSE = 0.62155 $.\n",
    "\n",
    "Although KNN's $ R^{2} $ is higher, it seems that the OLS's $ RMSE $ is lower. For the KNN Regressor's NRMSE to be such a large negative number, the mean of the y_test data must be a very small negative number. In the future I will re-evaluate this performance metric. I still believe it could be valuable not to standardize the numeric variables for the OLS so that the regression coefficients are still easily interpretable."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50634bbd5395cda3597decd691ad7117abc46b7293bd71e82600b7c628cb63ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('Py39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
